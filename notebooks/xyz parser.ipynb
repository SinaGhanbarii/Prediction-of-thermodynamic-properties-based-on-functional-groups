{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97fd457b",
   "metadata": {},
   "source": [
    "# **Phase 1**: Parsing `.xyz` files from the dataset and extract SMILES strings and target properties\n",
    "\n",
    "## Overview\n",
    "\n",
    "This document explains the procedure and functions used to process the QM9 dataset, which contains over 130,000 small organic molecules in `.xyz` files. The goal is to extract 12 quantum properties and SMILES strings from these files and convert them into a structured CSV dataset for machine learning applications.\n",
    "\n",
    "_Note that the `.tar.gz` file is sliced from the main QM9 dataset, and it contains 11001 small organic molecules!_\n",
    "\n",
    "\n",
    "## Data Preparation Procedure\n",
    "\n",
    "1. **Access the `.tar.gz` archive**  \n",
    "   Use Python’s `tarfile` module to read each `.xyz` file sequentially without fully extracting the archive.\n",
    "\n",
    "2. **Parse individual `.xyz` files**  \n",
    "   - Read the number of atoms and 17 quantum properties from the header.\n",
    "   - Select 12 relevant properties (electronic and thermodynamic) for prediction.\n",
    "   - Extract the canonical SMILES string from the penultimate line.\n",
    "\n",
    "3. **Error Handling**  \n",
    "   Use `try-except` blocks to skip files with malformed data or missing SMILES, and log errors without stopping the entire process.\n",
    "\n",
    "4. **Data Assembly**  \n",
    "   Create a dictionary of `{index, smiles, 12 properties}` for each molecule, store in a list, convert to a Pandas DataFrame, and save as a CSV.\n",
    "\n",
    "\n",
    "## Code Explanation\n",
    "\n",
    "### 1. Imports and Configurations\n",
    "\n",
    "- **Libraries:** `tarfile`, `pathlib`, `pandas`, `tqdm`, `logging`, `rdkit.Chem`, `tempfile`, `uuid`.\n",
    "- **Logging:** Configured to show timestamps and levels for process visibility.\n",
    "- **Target Properties:** Defined in `PROP_LABELS`, ignoring 3 rotational constants.\n",
    "\n",
    "\n",
    "### 1. Function `parse_qm9_xyz(xyz_path)`\n",
    "\n",
    "**Purpose:**  \n",
    "Reads one `.xyz` file and returns a dictionary with the molecule’s index, SMILES, and 12 selected quantum properties.\n",
    "\n",
    "**Steps:**  \n",
    "- Reads file into lines.\n",
    "- Extracts molecule index and properties from the second line (header).\n",
    "- Parses 12 properties into floats, stores them in a dictionary.\n",
    "- Extracts the SMILES string from the penultimate line.\n",
    "- Returns a dictionary of the molecule data.\n",
    "\n",
    "\n",
    "### 3. Function `process_tar_gz(tar_path, output_csv)`\n",
    "\n",
    "**Purpose:**  \n",
    "Processes a `.tar.gz` archive of QM9 `.xyz` files, parses each using `parse_qm9_xyz()`, and saves the dataset as a CSV file.\n",
    "\n",
    "**Steps:**  \n",
    "- Opens the archive and finds `.xyz` files.\n",
    "- Uses a temporary directory to extract and process each file.\n",
    "- For each file:\n",
    "  - Reads content, writes to a temp file.\n",
    "  - Calls `parse_qm9_xyz` to extract data.\n",
    "  - Appends valid records to a list.\n",
    "  - Deletes temp file.\n",
    "- After processing all files:\n",
    "  - Cleans up temp directory.\n",
    "  - Saves records as a DataFrame to CSV, sorted by index.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d324776",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 17:19:22,684 - INFO - Found 11001 .xyz files in dataset.tar.gz\n",
      "Processing .xyz files: 100%|██████████| 11001/11001 [06:27<00:00, 28.36it/s]\n",
      "2025-05-02 17:25:50,928 - INFO - Saved dataset with 11001 records to qm9_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Import the required Libraries\n",
    "import tarfile\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from rdkit import Chem\n",
    "import tempfile\n",
    "import uuid\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# keep only the 12 targets we care about\n",
    "PROP_LABELS = [\n",
    "    \"mu\", \"alpha\",                  # dipole moment (D), polarizability (Å³)\n",
    "    \"homo\", \"lumo\", \"gap\",          # orbital energies (Ha) and gap (Ha)\n",
    "    \"r2\",                           # <R²> (a₀²)\n",
    "    \"zpve\",                         # zero‑point vibrational energy (Ha)\n",
    "    \"U0\", \"U\", \"H\", \"G\",            # energies / enthalpy / free energy (Ha)\n",
    "    \"Cv\"                            # heat capacity (cal mol‑¹ K‑¹)\n",
    "]\n",
    "\n",
    "IGNORED = 3                         # rotA, rotB, rotC -> Skipped Properties \n",
    "\n",
    "def parse_qm9_xyz(xyz_path: str | Path) -> dict:\n",
    "    \"\"\"\n",
    "    Read one QM9‑style .xyz file and return:\n",
    "        {\n",
    "            'index' : 3895,\n",
    "            'smiles': 'O=C1C=CON=N1',\n",
    "            'props' : {label: value, …}   # the 12 targets (rotA/B/C omitted)\n",
    "        }\n",
    "    \"\"\"\n",
    "    lines = Path(xyz_path).read_text().splitlines()\n",
    "    \n",
    "    n_atoms = int(lines[0])                 # sanity‑check only\n",
    "    header_parts = lines[1].split('\\t')     # header parts are tab-separated\n",
    "\n",
    "    # “gdb 3895” → tag = 'gdb', idx = 3895\n",
    "    tag, idx = header_parts[0].split()      # split on whitespace\n",
    "    idx = int(idx)                          # convert index to integer\n",
    "\n",
    "    # Skip the first three values, then take the next 12\n",
    "    start = 1 + IGNORED                    # 1 = first value column after “gdb idx”\n",
    "    end   = start + len(PROP_LABELS)\n",
    "    prop_values = list(map(float, header_parts[start:end]))     # make a list of properties\n",
    "    props = dict(zip(PROP_LABELS, prop_values))\n",
    "\n",
    "    smiles = lines[-2].split('\\t')[0]      # first token on the penultimate line\n",
    "\n",
    "    return {\"index\": idx, \"smiles\": smiles, \"props\": props}\n",
    "\n",
    "\n",
    "def process_tar_gz(tar_path: str | Path, output_csv: str | Path) -> None:\n",
    "    \"\"\"\n",
    "    Process a .tar.gz file containing QM9 .xyz files and save the dataset to a CSV.\n",
    "\n",
    "    Args:\n",
    "        tar_path: Path to the .tar.gz file.\n",
    "        output_csv: Path to save the output CSV file.\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    temp_dir = Path(tempfile.gettempdir()) / f\"qm9_processing_{uuid.uuid4()}\"\n",
    "\n",
    "    try:\n",
    "        # Create temporary directory\n",
    "        temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        with tarfile.open(tar_path, \"r:gz\") as tar:\n",
    "            xyz_files = [member for member in tar.getmembers() if member.name.endswith(\".xyz\")]\n",
    "            logger.info(f\"Found {len(xyz_files)} .xyz files in {tar_path}\")\n",
    "\n",
    "            for member in tqdm(xyz_files, desc=\"Processing .xyz files\"):\n",
    "                try:\n",
    "                    f = tar.extractfile(member)         # Extract the file from the tar\n",
    "                    if f is None:\n",
    "                        logger.warning(f\"Could not extract {member.name}\")\n",
    "                        continue\n",
    "\n",
    "                    # Use unique temporary file name\n",
    "                    temp_xyz = temp_dir / f\"{uuid.uuid4()}.xyz\"\n",
    "                    content = f.read().decode(\"utf-8\")\n",
    "                    temp_xyz.write_text(content)\n",
    "\n",
    "                    result = parse_qm9_xyz(temp_xyz)    # Parse the extracted .xyz file\n",
    "                    if result:\n",
    "                        record = {\"index\": result[\"index\"], \"smiles\": result[\"smiles\"]} # Initialize record with index and smiles\n",
    "                        record.update(result[\"props\"])\n",
    "                        records.append(record)\n",
    "                    else:\n",
    "                        logger.warning(f\"Skipping {member.name}: Parsing failed\")\n",
    "\n",
    "                    # Clean up temporary file\n",
    "                    temp_xyz.unlink()\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error processing {member.name}: {e}\")\n",
    "                    continue\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error opening tar file {tar_path}: {e}\")\n",
    "        return\n",
    "    finally:\n",
    "        # Clean up temporary directory\n",
    "        try:\n",
    "            for temp_file in temp_dir.glob(\"*.xyz\"):\n",
    "                temp_file.unlink()\n",
    "            temp_dir.rmdir()\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error cleaning up temporary directory {temp_dir}: {e}\")\n",
    "\n",
    "    if records:\n",
    "        df = pd.DataFrame(records)          # Create DataFrame from records\n",
    "        columns = [\"index\", \"smiles\"] + PROP_LABELS     # Define the order of columns\n",
    "        df = df[columns]                # Reorder DataFrame columns\n",
    "        df = df.sort_values(\"index\")    # Sort DataFrame by index\n",
    "        df.to_csv(output_csv, index=False)      # Save DataFrame to CSV\n",
    "        logger.info(f\"Saved dataset with {len(df)} records to {output_csv}\")\n",
    "    else:\n",
    "        logger.warning(\"No valid records processed.\")\n",
    "\n",
    "\n",
    "# Main execution block\n",
    "if __name__ == \"__main__\":\n",
    "    tar_path = \"dataset.tar.gz\"  # The provided .tar.gz file\n",
    "    output_csv = \"qm9_dataset.csv\"  # Output CSV file\n",
    "    process_tar_gz(tar_path, output_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
